{
    "policy_model": {
            "Qwen2-72B-Instruct": {
                "path_to_model": "/mnt/data/haiye/llms/Qwen2-72B-Instruct",
                "path_to_chat_template": "/mnt/data/haiye/ensemble_inference/ensemble_inference/chat_templates/Qwen2-72B-instruct.jinja",
                "stop_tokens": "['<|im_end|>']",
                "api_key": "27223hisdihisd923jhik3hsdhuj323hsuejsijsd237",
                "port": 8002,
                "GPU": "0,1,2,3",
                "gpu_utilize": 0.9,
                "host": "dlc1lru4g60avg79-master-0"
        },
        "Llama-3.1-70B-Instruct": {
                "path_to_model": "/mnt/data/haiye/llms/Meta-Llama-3.1-70B-Instruct/",
                "path_to_chat_template": "/mnt/data/haiye/ensemble_inference/ensemble_inference/chat_templates/llama-3.1-70b-instruct.jinja",
                "stop_tokens": "['<|eot_id|>']",
                "api_key": "2723hsduj323hsuejsijsd237",
                "port": 8001,
                "GPU": "4,5,6,7",
                "gpu_utilize": 0.9,
                "host": "dlchtt7gmahrjf5p-master-0"
        },
        "Mixtral-8x22B-Instruct-v0.1": {
                "path_to_model": "/mnt/data/haiye/llms/Mixtral-8x22B-Instruct-v0.1",
                "path_to_chat_template": "/mnt/data/haiye/ensemble_inference/ensemble_inference/chat_templates/Mixtral-8x22B-Instruct-v0.1.jinja",
                "stop_tokens": "['</s>']",
                "api_key": "238sdhidhhisd82y3n",
                "port": 8000,
                "GPU": "0,1,2,3",
                "gpu_utilize": 0.9,
                "host": "dlchtt7gmahrjf5p-master-0"
        },
        "Yi-1.5-34B-Chat-16K": {
                "path_to_model": "/mnt/data/haiye/llms/Yi-1.5-34B-Chat-16K",
                "path_to_chat_template": "/mnt/data/haiye/ensemble_inference/ensemble_inference/chat_templates/Yi-1.5-34B-chat-16k.jinja",
                "stop_tokens": "['<|im_end|>']",
                "api_key": "27223hisdihisd923jhi82378k3hsejsijsd237",
                "port": 8003,
                "GPU": "4,5",
                "gpu_utilize": 0.9,
                "host": "dlc1lru4g60avg79-master-0"
        }
    },
    "reward_model": {"name": "ArmoRM", "path": "/mnt/data/haiye/llms/ArmoRM-Llama3-8B-v0.1/models--RLHFlow--ArmoRM-Llama3-8B-v0.1/snapshots/86323c8a6543c7fac07e9b0583b9443978b1e3a3", "GPU": "7" }
}